\section{Background}
\label{sec:Background}

The type system considered in this paper is a variant of the marked lambda calculus (MLC), introduced recently by \citet{DBLP:journals/pacmpl/ZhaoMDBPO24}. The marked lambda calculus combines \textbf{bidirectional typing} and \textbf{gradual typing} to achieve ``total type error localization and recovery,'' that is, the ability to localize type errors occurring throughout a program, without the presence of one error preventing the localization of another. The key components of this approach are summarized below. 

\paragraph{Bidirectional Typing} Bidirectional typing is an approach to type checking that splits the ordinary typing judgement into two judgements: an analytic judgment $\ctx\vdash e\Leftarrow\tau$ for checking whether the expression $e$ has type $\tau$ under context $\ctx$, and a synthetic judgment $\ctx\vdash e\Rightarrow\tau$, which infers a type from $e$~\cite{DBLP:journals/csur/DunfieldK21,pierce2000}. 
% Of course, there are innumerable extensions and embellishments to this simple scheme. 
The inference rules for the analytic and synthetic judgments directly specify a typing algorithm, and because of the locality of the flow of typing information, errors are naturally localized to the AST node where analysis or synthesis fails, unlike with unification-based inference. \citet{DBLP:journals/pacmpl/ZhaoMDBPO24} also give a unification-based type inference system on top of the bidirectionally typed core, but we do not consider this extension in this paper.

\paragraph{Gradual Typing} Gradual typing allows type checking intermixed typed and untyped code. The gradually typed lambda calculus extends the simply typed lambda calculus with the unknown (or dynamic) type, $\THole$, and replaces type equality with a type consistency relation~\cite{siek2006,siek2015}. The unknown type is consistent with every type. In live programming environments, gradual typing allows the type checker to handle type-incorrect programs that occur as the user edits.

% The unknown type can be treated as any other type for the purposes of type checking. For instance, if an expression is expected to have type $\tau_1$, and it is found to have type $\tau_2$, where the simply typed lambda calculus would check for \textit{equality} between these types, the gradually typed lambda calculus checks for \textit{consistency}. Consistency is like structural equality on types, but with the property that the gradual type is consistent with any other type. For example, $\TArrow{\THole}{\TNum}$ is consistent with $\TArrow{\TBool}{~\THole}$. 

\paragraph{Error Marks} The marked lambda calculus centers around the \textit{marking} procedure, a total function that transforms an ordinary expression $e$ into a marked expression $\check{e}$ by inserting error marks. Error marks can be attached to an expression to indicate the presence and nature of a type error localized to that expression. Intuitively, error marks are formal representations of the ``red squiggles'' one might see in a program editor.

The marking procedure is defined bidirectionally, with an analytic marking judgment $\ctx\vdash \MarkProg{e}{\check{e}}\Leftarrow\tau$ and a synthetic marking judgment $\ctx\vdash \MarkProg{e}{\check{e}}\Rightarrow\tau$. These have the same interpretations as the ordinary bidirectional judgments, but with the additional output $\check{e}$ (pronounced ``$e$ check'') and the additional property of specifying total functions. Any input program $e$, no matter how ill-typed, can be marked in either mode. The key to this totality is the use of the gradual type to recover from localized errors. Where a type error would occur in a simple type system, a term is assigned the unknown type in the marked lambda calculus. This allows typing to proceed optimistically, as the unknown type is consistent with all types and will not introduce additional downstream errors. The following example shows the case of a number literal applied to a free variable; the number is marked for synthesizing a non-function type while in function position, the variable is marked as free, and the program synthesizes the unknown type. Here, $\ECMarked{e}{}{}$ is a marked expression and the subscripts and superscripts are simply symbolic representations of the ``error message''.
\[
\centering
\emptyset\vdash \MarkProg{1~\VV}{\ECApSynNonMatchedArrow{1}{\ECFree{\VV}}}\Rightarrow~\THole
\]

% \subsection{Comparison with Prior Presentation}
% The variant of the marked lambda calculus defined in this section, the marked and annotated lambda calculus (MALC), differs structurally from the original marked lambda calculus (MLC), while implementing an equivalent type theory. The principal difference is that marks in MLC are represented as unary constructors wrapped around the location of the error. They are only present in the case of a static error, with an absence of mark nodes corresponding to an absence of static errors. In MALC marks are modeled as boolean data on term constructors indicating whether or not a static error has been found, and with the syntactic position of the mark determining what kind of error it indicates. 
% % The other difference is that marked MALC expressions contain annotated synthesized and analyzed types in the syntax, where these were implicit in the MLC. 

% The new mark representation makes it convenient for the side conditions (context lookup, type consistency, etc.) to be total functions that additionally return marks, rather than partial functions. This allows the marking rules to be uniform across cases of failure and success; where the original system needed an extra marking rule for each possible error on a given syntactic form, this system represents the same logic in one marking rule by factoring the alternative cases into the side conditions. 

% The impetus for this innovation is that the complexity of the incremental theory that follows is roughly proportional to the complexity of the marking judgments in the base theory. The side conditions, on the other hand, are more or less orthogonal to the incremental theory, so their complexity is not as amplified. The uniformity of marking rules enabled by this refactor cleanly separates the incremental logic from the static error logic. 
